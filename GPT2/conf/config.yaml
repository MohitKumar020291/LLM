# conf/config.yaml

train_model: true
continue_training: false
estimate_loss_only: false
generate: false

training_corpus_urls:
  - https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt

#path for the mounted folder
training_corpus_path: null

tokenizer_path: Tokenizer/Cache/Tokenizers/fs_tokenizer.pkl
model_path: GPT2/Cache/gpt_s.pth

# Training hyperparameters
batch_size: 64
block_size: 256
train_size: 0.9
learning_rate: 3e-4
warmup_iters: 500
max_iters: 2000
eval_interval: 500
eval_iters: 200

# DDP / runtime
num_workers: 4
pin_memory: true